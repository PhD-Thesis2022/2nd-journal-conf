{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6252fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42) # Used to always train de model in a same way to make assumptions\n",
    "import numpy as np\n",
    "from alive_progress import alive_bar\n",
    "import time\n",
    "from keras import backend as K\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63675e70",
   "metadata": {},
   "source": [
    "# Choice of the dataset & attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41173b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Loading\n",
    "\n",
    "# Select here the Dataset and the botnet attack\n",
    "'''ds = \"CICIDS2018\"\n",
    "botnet = [\"Zeus_Ares\"]'''\n",
    "\n",
    "ds = \"CTU\"\n",
    "botnet = [\"Neris\", \"Rbot\", \"Virut\"]\n",
    "\n",
    "attackindex=0 # index of botnet attack in the previous list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a9c432",
   "metadata": {},
   "source": [
    "# Dataset loading & Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d17c2b",
   "metadata": {},
   "source": [
    "## If not yet generated the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d2789d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2582434\n",
      "60632\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'mal = pd.DataFrame()\\nfor bot in botnet:\\n    mal_temp = pd.read_csv(\"DReLAB/{}/malicious/{}.csv\".format(ds, bot), index_col = 0)\\n    mal = pd.concat([mal, mal_temp], ignore_index = True)\\n    \\nn_mal = len(mal)\\nprint(n_mal)'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get benign samples from the selected dataset ds\n",
    "ben = pd.read_csv(\"DReLAB/{}/benign.csv\".format(ds), index_col = 0)\n",
    "\n",
    "n_ben = len(ben)\n",
    "print(n_ben)\n",
    "\n",
    "# load target attack traffic (for testing & adversarial instances generation)\n",
    "# Get malicious samples belonging to the chosen botnet from the selected dataset\n",
    "mal = pd.read_csv(\"DReLAB/{}/malicious/{}.csv\".format(ds, botnet[attackindex]), index_col = 0)\n",
    "n_mal = len(mal)\n",
    "print(n_mal)\n",
    "\n",
    "# Load dataset containing all attacks (for training)\n",
    "'''mal = pd.DataFrame()\n",
    "for bot in botnet:\n",
    "    mal_temp = pd.read_csv(\"DReLAB/{}/malicious/{}.csv\".format(ds, bot), index_col = 0)\n",
    "    mal = pd.concat([mal, mal_temp], ignore_index = True)\n",
    "    \n",
    "n_mal = len(mal)\n",
    "print(n_mal)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ea0a63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benign in dataset: 60632\n",
      "Malicious in dataset: 60632\n",
      "Ben / Mal Ratio: 1.0\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: 'CTU/datasets/<attack_name> or <training>/defender_dataset.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12688/141990122.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m# Datasets saving\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mpkl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefender_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/datasets/<attack_name> or <training>/defender_dataset.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[0mpkl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattacker_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/datasets/<attack_name> or <training>/attacker_dataset.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument: 'CTU/datasets/<attack_name> or <training>/defender_dataset.pkl'"
     ]
    }
   ],
   "source": [
    "# Pre-processing \n",
    "# Remove the infinity value in ratio in out when in and out bytes = 0, replaced by 0 because 0/0\n",
    "\n",
    "ben.loc[(ben[\"OutBytes\"] == 0) & (ben[\"InBytes\"] == 0), \"RatioOutIn\"] = 0\n",
    "mal.loc[(mal[\"OutBytes\"] == 0) & (mal[\"InBytes\"] == 0), \"RatioOutIn\"] = 0\n",
    "\n",
    "# Obtain the dataset in a 1:1 benign/malicious ratio\n",
    "if (n_ben // 1) >= n_mal:\n",
    "    dataset_ben = ben.sample(n_mal * 1)\n",
    "    dataset = pd.concat([dataset_ben, mal], ignore_index = True)\n",
    "    print(\"Benign in dataset: {}\".format(len(dataset_ben)))\n",
    "    print(\"Malicious in dataset: {}\".format(len(mal)))\n",
    "    print(\"Ben / Mal Ratio: {}\".format(len(dataset_ben) / len(mal)))\n",
    "    \n",
    "else:\n",
    "    dataset_mal = mal.sample(n_ben // 1)\n",
    "    dataset = pd.concat([ben, dataset_mal], ignore_index = True)\n",
    "    print(\"Benign in dataset: {}\".format(len(ben)))\n",
    "    print(\"Malicious in dataset: {}\".format(len(dataset_mal)))\n",
    "    print(\"Ben / Mal Ratio: {}\".format(len(ben) / len(dataset_mal)))\n",
    "    \n",
    "# Data Splitting, No cross validation because too slow due to the big dataset and model complexity \n",
    "# Split general dataset to provide separate dataset for attacker and defender\n",
    "defender_dataset, attacker_dataset = train_test_split(dataset, random_state=42, stratify=dataset.Label, shuffle=True, test_size=0.5)\n",
    "\n",
    "# Datasets saving \n",
    "pkl.dump(defender_dataset, open(ds + '/datasets/<attack_name> or <training>/defender_dataset.pkl', 'wb'))\n",
    "pkl.dump(attacker_dataset, open(ds + '/datasets/<attack_name> or <training>/attacker_dataset.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e48ec99",
   "metadata": {},
   "source": [
    "## If datasets already saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0d27976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets Loading\n",
    "defender_dataset = pkl.load(open(ds + '/datasets/training/defender_dataset.pkl', 'rb'))\n",
    "attacker_dataset = pkl.load(open(ds + '/datasets/training/attacker_dataset.pkl', 'rb'))\n",
    "\n",
    "# Substitute = Attacker\n",
    "# Split x_train and x_test to train and evaluate substitute and defender models \n",
    "X_train_defender, X_test_defender, y_train_defender, y_test_defender = train_test_split(defender_dataset.drop(columns = [\"Label\"]), defender_dataset.Label, test_size=0.25)\n",
    "X_train_substitute, X_test_substitute, y_train_substitute, y_test_substitute = train_test_split(attacker_dataset.drop(columns = [\"Label\"]), attacker_dataset.Label, test_size=0.25)\n",
    "\n",
    "# Recover the complete test datasets with labels for the aversarial instances generation and evaluation\n",
    "test_defender = pd.concat([X_test_defender, y_test_defender], axis=1)\n",
    "test_substitute = pd.concat([X_test_substitute, y_test_substitute], axis=1)\n",
    "train_defender = pd.concat([X_train_defender, y_train_defender], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "925ca492",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benco\\anaconda3\\envs\\optimalnidsattack\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\benco\\anaconda3\\envs\\optimalnidsattack\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\benco\\anaconda3\\envs\\optimalnidsattack\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\benco\\anaconda3\\envs\\optimalnidsattack\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Pre-processing\n",
    "\n",
    "## Data Normalization\n",
    "# https://stackoverflow.com/questions/49444262/normalize-data-before-or-after-split-of-training-and-testing-data\n",
    "# Data normalized on the corresponding training set\n",
    "\n",
    "# For attacker DNN\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train_substitute.to_numpy()) # to numpy to avoid the warning later when we predict with a numpy instead of dataframe\n",
    "X_train_substitute_scaled = scaler.transform(X_train_substitute)\n",
    "X_test_substitute_scaled = scaler.transform(X_test_substitute)  # normalize test set on training set\n",
    "\n",
    "# For defender DNN\n",
    "scaler2 = MinMaxScaler()\n",
    "scaler2.fit(X_train_defender.to_numpy())\n",
    "X_train_defender_scaled = scaler2.transform(X_train_defender)\n",
    "X_test_defender_scaled = scaler2.transform(X_test_defender) # normalize test set on training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de61658a",
   "metadata": {},
   "source": [
    "# Models Initialization & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62fe89a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "904/904 [==============================] - 6s 4ms/step - loss: 0.1368 - categorical_accuracy: 0.9296\n",
      "Epoch 2/10\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1199 - categorical_accuracy: 0.9388\n",
      "Epoch 3/10\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1133 - categorical_accuracy: 0.9434\n",
      "Epoch 4/10\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1078 - categorical_accuracy: 0.9467\n",
      "Epoch 5/10\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1053 - categorical_accuracy: 0.9490\n",
      "Epoch 6/10\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1006 - categorical_accuracy: 0.9539\n",
      "Epoch 7/10\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.0943 - categorical_accuracy: 0.9585\n",
      "Epoch 8/10\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.0905 - categorical_accuracy: 0.9615\n",
      "Epoch 9/10\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.0857 - categorical_accuracy: 0.9646\n",
      "Epoch 10/10\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.0845 - categorical_accuracy: 0.9654\n",
      "941/941 [==============================] - 2s 2ms/step - loss: 0.0854 - categorical_accuracy: 0.9658\n",
      "INFO:tensorflow:Assets written to: CTU/models/dnndefender\\assets\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multilabel-indicator and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12688/1403489457.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_defender_scaled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[0my_pred_vect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_test_defender_ohe_tf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_pred_vect\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\optimalnidsattack\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2074\u001b[0m     \"\"\"\n\u001b[0;32m   2075\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2076\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2077\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2078\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\optimalnidsattack\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m     94\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[0;32m     95\u001b[0m                 \u001b[0mtype_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and binary targets"
     ]
    }
   ],
   "source": [
    "# Model 1 initialization and training - DNN (DEFENDER)\n",
    "\n",
    "# One-hot encoding and convertion into tensors because TensorFlow DNN\n",
    "y_train_defender_ohe = pd.get_dummies(y_train_defender)\n",
    "y_train_defender_ohe_tf = tf.convert_to_tensor(y_train_defender_ohe, np.float32)\n",
    "\n",
    "y_test_defender_ohe = pd.get_dummies(y_test_defender)\n",
    "y_test_defender_ohe_tf = tf.convert_to_tensor(y_test_defender_ohe, np.float32)\n",
    "\n",
    "# Calculate the weights for each class so that we can balance the data. Safe umbalanced data\n",
    "# new loss function\n",
    "# https://stackoverflow.com/questions/43390162/class-weights-in-binary-classification-model-with-keras\n",
    "def weighted_binary_crossentropy( y_true, y_pred, weight=1. ) :\n",
    "    y_true = K.clip(y_true, K.epsilon(), 1-K.epsilon())\n",
    "    y_pred = K.clip(y_pred, K.epsilon(), 1-K.epsilon())\n",
    "    logloss = -(y_true * K.log(y_pred) * weight + (1 - y_true) * K.log(1 - y_pred))\n",
    "    return K.mean( logloss, axis=-1)\n",
    "\n",
    "output_number = 2\n",
    "eval_metric = 'categorical_accuracy'\n",
    "activ_out = 'softmax'\n",
    "neurons_number = 256\n",
    "lr = 0.01\n",
    "features_number = X_train_defender_scaled.shape[1]\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(neurons_number, input_shape=(features_number,), activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(neurons_number, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(output_number, activation=activ_out)\n",
    "])\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "    loss = weighted_binary_crossentropy,\n",
    "    metrics=[eval_metric]\n",
    ")\n",
    "\n",
    "model.fit(x=X_train_defender_scaled, y=y_train_defender_ohe_tf, epochs=10, batch_size=100, verbose=1)\n",
    "model.evaluate(x=X_test_defender_scaled, y=y_test_defender_ohe_tf, verbose=1)\n",
    "\n",
    "# Model saving \n",
    "tf.keras.models.save_model(model, ds + '/models/dnndefender')\n",
    "\n",
    "# Uncomment all before if you already trained the model\n",
    "# Model Loading\n",
    "# model = tf.keras.models.load_model(ds + '/models/dnndefender', custom_objects={'weighted_binary_crossentropy': weighted_binary_crossentropy})\n",
    "\n",
    "# Evaluation\n",
    "y_pred = model.predict(X_test_defender_scaled)\n",
    "y_pred_vect = np.argmax(y_pred,1)\n",
    "print(classification_report(y_true=y_test_defender, y_pred=y_pred_vect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d0f72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Initialization and training - Random Forest (DEFENDER)\n",
    "\n",
    "# Bootstrap = True by default (split dataset to train sub model with sub dataset)\n",
    "# Max feature = sqrt(nb feature), means that when it can, the best split is sqrt(f)\n",
    "model2 = RandomForestClassifier(n_estimators = 200, n_jobs = -1, random_state=0)\n",
    "\n",
    "# No need to scale data as in Neural Network\n",
    "model2.fit(X_train_defender, y_train_defender)\n",
    "\n",
    "# Model saving \n",
    "pkl.dump(model2, open(ds + '/models/rfdefender.pkl', 'wb'))\n",
    "\n",
    "# Uncomment all before if you already trained the model\n",
    "# Model Loading\n",
    "# model2 = pkl.load(open(ds + '/models/rfdefender.pkl', 'rb'))\n",
    "\n",
    "# Evaluation\n",
    "pred = model2.predict(X_test_defender)\n",
    "\n",
    "# Compute f1, precision and recall score.\n",
    "matrix = classification_report(y_true=y_test_defender, y_pred=pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e2fdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3 - ADABoost (DEFENDER)\n",
    "model3 = AdaBoostClassifier(n_estimators=200, learning_rate=0.5, random_state=0)\n",
    "model3.fit(X_train_defender, y_train_defender)\n",
    "\n",
    "# Model saving \n",
    "pkl.dump(model3, open(ds + '/models/adaboostdefender.pkl', 'wb'))\n",
    "\n",
    "# Uncomment all before if you already trained the model\n",
    "# Model Loading\n",
    "# model3 = pkl.load(open(ds + '/models/adaboostdefender.pkl', 'rb'))\n",
    "\n",
    "# Evaluation\n",
    "pred = model3.predict(X_test_defender)\n",
    "matrix = classification_report(y_true=y_test_defender, y_pred=pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4327b7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 4 - KNN (DEFENDER)\n",
    "\n",
    "model4 = KNeighborsClassifier(n_neighbors=3)\n",
    "model4.fit(X_train_defender, y_train_defender)\n",
    "\n",
    "# Model saving \n",
    "pkl.dump(model4, open(ds + '/models/knndefender.pkl', 'wb'))\n",
    "\n",
    "# Uncomment all before if you already trained the model\n",
    "# Model Loading\n",
    "# model4 = pkl.load(open(ds + '/models/knndefender.pkl', 'rb'))\n",
    "\n",
    "# Evaluation\n",
    "pred = model4.predict(X_test_defender)\n",
    "matrix = classification_report(y_true=y_test_defender, y_pred=pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5994e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 5 - Logistic regression (DEFENDER)\n",
    "model5 = LogisticRegression(max_iter=1000, penalty=\"l1\", solver=\"saga\", random_state=0) # solver lbfgs dans paramètres\n",
    "model5.fit(X_train_defender_scaled, y_train_defender)\n",
    "\n",
    "# Model saving \n",
    "pkl.dump(model5, open(ds + '/models/lrdefender.pkl', 'wb'))\n",
    "\n",
    "# Uncomment all before if you already trained the model\n",
    "# Model Loading\n",
    "# model5 = pkl.load(open(ds + '/models/lrdefender.pkl', 'rb'))\n",
    "\n",
    "# Evaluation\n",
    "pred = model5.predict(X_test_defender_scaled)\n",
    "matrix = classification_report(y_true=y_test_defender, y_pred=pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fd38fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 6 -  Decision Tree (DEFENDER)\n",
    "model6 = DecisionTreeClassifier(criterion=\"entropy\", random_state=0)\n",
    "model6.fit(X_train_defender, y_train_defender)\n",
    "\n",
    "# Model saving \n",
    "pkl.dump(model6, open(ds + '/models/dtdefender.pkl', 'wb'))\n",
    "\n",
    "# Uncomment all before if you already trained the model\n",
    "# Model Loading\n",
    "# model6 = pkl.load(open(ds + '/models/dtdefender.pkl', 'rb'))\n",
    "\n",
    "# Evaluation\n",
    "pred = model6.predict(X_test_defender)\n",
    "matrix = classification_report(y_true=y_test_defender, y_pred=pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbba175",
   "metadata": {},
   "source": [
    "## Important - Do the same with different meta-parameters for the attacker with their corresponding dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5412224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "904/904 [==============================] - 4s 4ms/step - loss: 0.1424 - categorical_accuracy: 0.9263\n",
      "Epoch 2/10\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1262 - categorical_accuracy: 0.9325\n",
      "Epoch 3/10\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1217 - categorical_accuracy: 0.9346\n",
      "Epoch 4/10\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1184 - categorical_accuracy: 0.9364\n",
      "Epoch 5/10\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1157 - categorical_accuracy: 0.9392\n",
      "Epoch 6/10\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.1100 - categorical_accuracy: 0.9421\n",
      "Epoch 7/10\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.1063 - categorical_accuracy: 0.9485\n",
      "Epoch 8/10\n",
      "904/904 [==============================] - 3s 4ms/step - loss: 0.0999 - categorical_accuracy: 0.9538\n",
      "Epoch 9/10\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.0971 - categorical_accuracy: 0.9552\n",
      "Epoch 10/10\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.0907 - categorical_accuracy: 0.9600\n",
      "941/941 [==============================] - 2s 2ms/step - loss: 0.0935 - categorical_accuracy: 0.9583\n",
      "INFO:tensorflow:Assets written to: CTU/models/dnnattacker\\assets\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96     15135\n",
      "           1       0.93      0.99      0.96     14974\n",
      "\n",
      "    accuracy                           0.96     30109\n",
      "   macro avg       0.96      0.96      0.96     30109\n",
      "weighted avg       0.96      0.96      0.96     30109\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model 7 initialization and training - DNN (ATTACKER)\n",
    "\n",
    "# Pre-processing for the training\n",
    "y_train_substitute_ohe = pd.get_dummies(y_train_substitute)\n",
    "y_train_substitute_ohe_tf = tf.convert_to_tensor(y_train_substitute_ohe, np.float32)\n",
    "\n",
    "y_test_substitute_ohe = pd.get_dummies(y_test_substitute)\n",
    "y_test_substitute_ohe_tf = tf.convert_to_tensor(y_test_substitute_ohe, np.float32)\n",
    "\n",
    "# Calculate the weights for each class so that we can balance the data. Safe umbalanced data\n",
    "# new loss function\n",
    "# https://stackoverflow.com/questions/43390162/class-weights-in-binary-classification-model-with-keras\n",
    "def weighted_binary_crossentropy( y_true, y_pred, weight=1. ) :\n",
    "    y_true = K.clip(y_true, K.epsilon(), 1-K.epsilon())\n",
    "    y_pred = K.clip(y_pred, K.epsilon(), 1-K.epsilon())\n",
    "    logloss = -(y_true * K.log(y_pred) * weight + (1 - y_true) * K.log(1 - y_pred))\n",
    "    return K.mean( logloss, axis=-1)\n",
    "\n",
    "output_number = 2\n",
    "eval_metric = 'categorical_accuracy'\n",
    "activ_out = 'softmax'\n",
    "neurons_number = 128\n",
    "lr = 0.01\n",
    "features_number = X_train_substitute_scaled.shape[1]\n",
    "\n",
    "model7 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(neurons_number, input_shape=(features_number,), activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(neurons_number, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(neurons_number, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(output_number, activation=activ_out)\n",
    "])\n",
    "model7.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "    loss = weighted_binary_crossentropy,\n",
    "    metrics=[eval_metric]\n",
    ")\n",
    "\n",
    "\n",
    "model7.fit(x=X_train_substitute_scaled, y=y_train_substitute_ohe_tf, epochs=10, batch_size=100, verbose=1)\n",
    "model7.evaluate(x=X_test_substitute_scaled, y=y_test_substitute_ohe_tf, verbose=1)\n",
    "\n",
    "# Model saving \n",
    "tf.keras.models.save_model(model7, ds + '/models/dnnattacker')\n",
    "\n",
    "# Model Loading\n",
    "# model7 = tf.keras.models.load_model(ds + '/models/dnnattacker', custom_objects={'weighted_binary_crossentropy': weighted_binary_crossentropy})\n",
    "\n",
    "y_pred = model7.predict(X_test_substitute_scaled)\n",
    "y_pred_vect = np.argmax(y_pred,1)\n",
    "print(classification_report(y_true=y_test_substitute, y_pred=y_pred_vect))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f914d77c",
   "metadata": {},
   "source": [
    "# Evasion attack - Adversarial algorithm execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a966841a",
   "metadata": {},
   "source": [
    "## Configuration of the different settings for the generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b585195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the dataset where perform adversarial generation. Defender dataset is used for the defense\n",
    "dataset_input = test_substitute # From the attacker\n",
    "\n",
    "# Choose the model to generate adv example as parameter (depends of your chosen dataset)\n",
    "model_input = model7\n",
    "\n",
    "# The mask combinaisons that can be adapted in function of the studied domain. Depends of the manipulable factors\n",
    "combinaisons = [ # Don't take [0000] because not relevant, so 7 combinaisons. [0001] = duration, [0010] = totpkt et [1100] in/outbytes (most difficult to modify)\n",
    "    [0,0,0,1],\n",
    "    [0,0,1,0],\n",
    "    [0,0,1,1],\n",
    "    [0,1,0,0],\n",
    "    [0,1,0,1],\n",
    "    [0,1,1,0],\n",
    "    [0,1,1,1],\n",
    "    [1,0,0,0],\n",
    "    [1,0,0,1],\n",
    "    [1,0,1,0],\n",
    "    [1,0,1,1],\n",
    "    [1,1,0,0],\n",
    "    [1,1,0,1],\n",
    "    [1,1,1,0],\n",
    "    [1,1,1,1]\n",
    "]\n",
    "\n",
    "ratio_mean_out_in = []\n",
    "dif_mean_out_in = []\n",
    "\n",
    "vect = np.array([1.,1.])\n",
    "\n",
    "# Define max value of each modified feature in the general dataset to project too big values on these max\n",
    "# It's the max value of the attacker or defender dataset, specified in parameter\n",
    "max_dur = dataset_input['Dur'].max()\n",
    "max_pkts = dataset_input['TotPkts'].max()\n",
    "max_out = dataset_input['OutBytes'].max()\n",
    "max_in = dataset_input['InBytes'].max()\n",
    "\n",
    "# Used to generate Adv Ex. Don't take the label to generate adv ex\n",
    "ben_dataset = dataset_input.loc[dataset_input['Label'] == 0]\n",
    "mal_dataset = dataset_input.loc[dataset_input['Label'] == 1]\n",
    "\n",
    "# For the first method - Mean ratio used to have the distance between benign and malicious traffic\n",
    "ratio_mean_dur = mal_dataset[['Dur']].mean() / ben_dataset[['Dur']].mean()\n",
    "ratio_mean_dur = ratio_mean_dur[0]\n",
    "ratio_mean_pkts = mal_dataset[['TotPkts']].mean() / ben_dataset[['TotPkts']].mean()\n",
    "ratio_mean_pkts = ratio_mean_pkts[0]\n",
    "ratio_mean_out = mal_dataset[['OutBytes']].mean() / ben_dataset[['OutBytes']].mean()\n",
    "ratio_mean_out_in.append(ratio_mean_out[0])\n",
    "ratio_mean_in = mal_dataset[['InBytes']].mean() / ben_dataset[['InBytes']].mean()\n",
    "ratio_mean_out_in.append(ratio_mean_in[0])\n",
    "\n",
    "# Mean determination to determine during peturbation generation the direction of the perturbation (negative or positive)\n",
    "ben_mean_dur = ben_dataset['Dur'].mean()\n",
    "ben_mean_pkts = ben_dataset['TotPkts'].mean()\n",
    "ben_mean_out = ben_dataset['OutBytes'].mean()\n",
    "ben_mean_in = ben_dataset['InBytes'].mean()\n",
    "\n",
    "# For the second method, Mean difference used to have the Euclidian distance between benign and malicious traffic\n",
    "# We take the absolute value to avoid apposite perturbation\n",
    "dif_mean_dur = ben_dataset[['Dur']].mean() - mal_dataset[['Dur']].mean()\n",
    "dif_mean_dur = abs(dif_mean_dur[0])\n",
    "dif_mean_pkts = ben_dataset[['TotPkts']].mean() - mal_dataset[['TotPkts']].mean()\n",
    "dif_mean_pkts = abs(dif_mean_pkts[0])\n",
    "dif_mean_out = ben_dataset[['OutBytes']].mean() - mal_dataset[['OutBytes']].mean()\n",
    "dif_mean_out_in.append(abs(dif_mean_out[0]))\n",
    "dif_mean_in = ben_dataset[['InBytes']].mean() - mal_dataset[['InBytes']].mean()\n",
    "dif_mean_out_in.append(abs(dif_mean_in[0]))\n",
    "\n",
    "# Reduce the dataset for the tests to speed up the generation. Just take 10K instances here\n",
    "mal_dataset_reduced, not_used = train_test_split(mal_dataset.drop(columns = [\"Label\"]), shuffle=True, train_size=(10000/mal_dataset.shape[0]), random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc19196",
   "metadata": {},
   "source": [
    "## Adversarial algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056524c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For CICIDS\n",
    "\n",
    "adv_ex = []\n",
    "total_ex = []\n",
    "\n",
    "tot_nb_of_steps = [] # Used to know what the needed mean steps to create an adversarial example\n",
    "nb_of_needed_step = 0\n",
    "\n",
    "tot_masks = []# Used to know what the most used mask to create an adversarial example\n",
    "index_of_mask = 0\n",
    "\n",
    "max_ratio = dataset_input['RatioOutIn'].max() # Max value in RatioOutIn for the semantic constraints\n",
    "\n",
    "# compute the time taken\n",
    "start = time.process_time()\n",
    "with alive_bar(len(mal_dataset_reduced)) as bar:\n",
    "    # For each malicious instance\n",
    "    for index, row in mal_dataset_reduced.iterrows():\n",
    "        breaked = False\n",
    "        perturb_direction = []\n",
    "        \n",
    "        # Check the direction of perturbation for the 4 instance features\n",
    "        if(row[1] <= ben_mean_out):\n",
    "            perturb_direction.append(1)\n",
    "        else:\n",
    "            perturb_direction.append(-1)\n",
    "            \n",
    "        if(row[2] <= ben_mean_in):\n",
    "            perturb_direction.append(1)\n",
    "        else:\n",
    "            perturb_direction.append(-1)\n",
    "            \n",
    "        if(row[3] <= ben_mean_pkts):\n",
    "            perturb_direction.append(1)\n",
    "        else:\n",
    "            perturb_direction.append(-1)    \n",
    "            \n",
    "        if(row[0] <= ben_mean_dur): \n",
    "            perturb_direction.append(1)\n",
    "        else:\n",
    "            perturb_direction.append(-1)\n",
    "        \n",
    "        # Max 6 iterations of iterative perturbation to try to get benign instance. Can be changed (ex: 10 to have 10 - 100%) for the second method\n",
    "        for i in range(1, 7):\n",
    "            nb_of_needed_step += 1 # start directly at the round 1\n",
    "            # Iterate while not benign \n",
    "            if(breaked==False):\n",
    "                # For each 7 combinations of perturbations\n",
    "                for combi in combinaisons:\n",
    "                    index_of_mask += 1 # check which mask is used\n",
    "                    # add perturbation to the autorized features\n",
    "                    \n",
    "                    adv = np.array(row)\n",
    "                    \n",
    "                    # First method taking the mean ratio between attack and benign datasets to determine perturbation\n",
    "                    # Factor C here must be really more important               \n",
    "                    '''perturb1 = np.array(combi[0:2]) * (vect * ratio_mean_out_in * i * perturb_direction[0:2]) # Verify for CICIDS\n",
    "                    perturb2 = np.array(combi[2]) * (ratio_mean_pkts * i * perturb_direction[2])\n",
    "                    perturb3 = np.array(combi[3]) * (ratio_mean_dur * i * perturb_direction[3])'''\n",
    "                    \n",
    "                    # Second method taking the mean difference\n",
    "                    \n",
    "                    perturb1 = np.array(combi[0:2]) * (vect * dif_mean_out_in * (i*0.2) * perturb_direction[0:2])  # dunno how to avoid the error without vect\n",
    "                    perturb2 = np.array(combi[2]) * (dif_mean_pkts * (i*0.05) * perturb_direction[2])\n",
    "                    perturb3 = np.array(combi[3]) * (dif_mean_dur * (i*0.003) * perturb_direction[3])\n",
    "                    \n",
    "                    adv[1:3] = adv[1:3] + perturb1\n",
    "                    adv[3] = adv[3] + perturb2\n",
    "                    adv[0] = adv[0] + perturb3\n",
    "                    \n",
    "                    # Syntactic Constraints\n",
    "                    # Add projection on the max value present in the dataset to keep the physical limitation\n",
    "                    if(adv[0] > max_dur):\n",
    "                        adv[0] = max_dur\n",
    "                    if(adv[2] > max_out):\n",
    "                        adv[2] = max_out\n",
    "                    if(adv[1] > max_in):\n",
    "                        adv[1] = max_in\n",
    "                    if(adv[3] > max_pkts):\n",
    "                        adv[3] = max_pkts\n",
    "                                \n",
    "                    # Add the semantic contraints\n",
    "                    # Total number of Bytes in the communication. Sum of OutBytes and InBytes feature values.\n",
    "                    adv[4] = adv[1]+adv[2]\n",
    "                    # Average number of bytes exchanged per packet. Ratio between TotBytes and TotPkts.\n",
    "                    adv[5] = adv[4]/adv[3]\n",
    "                    # Average number of bytes exchanged per second. Ratio between TotBytes and Duration.\n",
    "                    adv[6] = adv[4]/adv[0]\n",
    "                    # Average number of packets exchanged per second. Ratio between TotPkts and Duration.\n",
    "                    adv[7] = adv[3]/adv[0]\n",
    "                    \n",
    "                    # Ratio between OutBytes and InBytes\n",
    "                    if(adv[1] == 0 and adv[2] != 0):\n",
    "                        adv[8] = max_ratio # It's the maximum value in the dataset to replace the infinity value\n",
    "                    # If In and Out = 0, ratio is 0. 0/0 (Maybe not necessary)\n",
    "                    if(adv[1] == 0 and adv[2] == 0):\n",
    "                        adv[8] = 0\n",
    "                    # Ratio by default when inbytes has a value x/y\n",
    "                    if(adv[1] != 0):\n",
    "                        adv[8] = adv[2]/adv[1]\n",
    "                    # if there is new bytes, normaly there is also at least 1 packet \n",
    "                    if(adv[3] == 0 and adv[4] > 0):\n",
    "                        adv[3] = 1 \n",
    "                    \n",
    "                    adv2 = [] # used to fit with the input of the model because normaly take a matrix, so need the matrix notation, even for a vector\n",
    "                    adv2.append(adv)\n",
    "                    \n",
    "                    adv2_scaled = scaler.transform(adv2) # For DNN, if not the case, must be commented\n",
    "                    test = model_input.predict(adv2_scaled) # For DNN\n",
    "                    test = np.argmax(test,1) # For DNN\n",
    "                    #test = model_input.predict(adv2) # For other model than DNN\n",
    "                    if (test == 0): # benign break\n",
    "                        adv_ex.append(adv) # adv_ex contains all adversarial examples that fool the classifier\n",
    "                        breaked = True\n",
    "                        tot_masks.append(index_of_mask)\n",
    "                        tot_nb_of_steps.append(nb_of_needed_step)\n",
    "                        break\n",
    "            index_of_mask = 0\n",
    "        nb_of_needed_step = 0            \n",
    "        total_ex.append(adv) # Total adversarial examples. append the final created adv ex that fool or not \n",
    "        bar()\n",
    "\n",
    "end = time.process_time()-start\n",
    "print(\"Time taken to generate: \" + str(end) + \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67c04e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|▎⚠︎                                      | (!) 61/10000 [1%] in 46.5s (1.31/s) \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12688/2805619128.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m                     \u001b[0madv2_scaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madv2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# For DNN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m                     \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madv2_scaled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m                     \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# For DNN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m                     \u001b[1;31m#test = model_input.predict(adv2) # For other model than DNN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\optimalnidsattack\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\optimalnidsattack\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1785\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Single epoch.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1786\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1787\u001b[1;33m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1788\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1789\u001b[0m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\optimalnidsattack\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36msteps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1248\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1249\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1250\u001b[1;33m       \u001b[0moriginal_spe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1251\u001b[0m       can_run_full_execution = (\n\u001b[0;32m   1252\u001b[0m           \u001b[0moriginal_spe\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\optimalnidsattack\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    643\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    646\u001b[0m     raise NotImplementedError(\n\u001b[0;32m    647\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
      "\u001b[1;32m~\\anaconda3\\envs\\optimalnidsattack\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mread_value\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    718\u001b[0m     \"\"\"\n\u001b[0;32m    719\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Read\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 720\u001b[1;33m       \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_variable_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    721\u001b[0m     \u001b[1;31m# Return an identity so it can get placed on whatever device the context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m     \u001b[1;31m# specifies instead of the device where the variable is.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\optimalnidsattack\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m_read_variable_op\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    697\u001b[0m           \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\optimalnidsattack\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mread_and_set_handle\u001b[1;34m()\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 689\u001b[1;33m       result = gen_resource_variable_ops.read_variable_op(\n\u001b[0m\u001b[0;32m    690\u001b[0m           self.handle, self._dtype)\n\u001b[0;32m    691\u001b[0m       \u001b[0m_maybe_set_handle_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\optimalnidsattack\\lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py\u001b[0m in \u001b[0;36mread_variable_op\u001b[1;34m(resource, dtype, name)\u001b[0m\n\u001b[0;32m    467\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    468\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 469\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m    470\u001b[0m         _ctx, \"ReadVariableOp\", name, resource, \"dtype\", dtype)\n\u001b[0;32m    471\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# For CTU\n",
    "\n",
    "adv_ex = []\n",
    "total_ex = []\n",
    "\n",
    "tot_nb_of_steps = [] # Used to know what the needed mean steps to create an adversarial example\n",
    "nb_of_needed_step = 0\n",
    "\n",
    "tot_masks = []# Used to know what the most used mask to create an adversarial example\n",
    "index_of_mask = 0\n",
    "\n",
    "max_ratio = dataset_input['RatioOutIn'].max() # Max value in RatioOutIn for the semantic constraints\n",
    "start = time.process_time()\n",
    "\n",
    "with alive_bar(len(mal_dataset_reduced)) as bar:\n",
    "    # For each malicious instance\n",
    "    for index, row in mal_dataset_reduced.iterrows():\n",
    "        breaked = False\n",
    "        perturb_direction = []\n",
    "        \n",
    "        # Check the direction of perturbation for the 4 instance features\n",
    "        if(row[6] <= ben_mean_out): # Out\n",
    "            perturb_direction.append(1)\n",
    "        else:\n",
    "            perturb_direction.append(-1)\n",
    "            \n",
    "        if(row[7] <= ben_mean_in): # In\n",
    "            perturb_direction.append(1)\n",
    "        else:\n",
    "            perturb_direction.append(-1)\n",
    "            \n",
    "        if(row[8] <= ben_mean_pkts): # TotPkts\n",
    "            perturb_direction.append(1)\n",
    "        else:\n",
    "            perturb_direction.append(-1)    \n",
    "            \n",
    "        if(row[2] <= ben_mean_dur): # Dur\n",
    "            perturb_direction.append(1)\n",
    "        else:\n",
    "            perturb_direction.append(-1)\n",
    "        \n",
    "        # Max 6 iterations of iterative perturbation to try to get benign instance\n",
    "        for i in range(1, 7):\n",
    "            nb_of_needed_step += 1 # start directly at the round 1\n",
    "            # Iterate while not benign \n",
    "            if(breaked==False):\n",
    "                # For each 7 combinations of perturbations\n",
    "                for combi in combinaisons:\n",
    "                    index_of_mask += 1 # check which mask is used\n",
    "                    # add perturbation to the autorized features\n",
    "                    \n",
    "                    adv = np.array(row)\n",
    "                    \n",
    "                    # First method taking the mean ratio between attack and benign datasets to determine perturbation\n",
    "                    '''perturb1 = np.array(combi[0:2]) * (vect * ratio_mean_out_in * (i*5) * perturb_direction[0:2])\n",
    "                    perturb2 = np.array(combi[2]) * (ratio_mean_pkts * (i*5) * perturb_direction[1])\n",
    "                    perturb3 = np.array(combi[3]) * (ratio_mean_dur * (i*5) * perturb_direction[2])'''\n",
    "                    \n",
    "                    # Second method taking the mean difference\n",
    "                    perturb1 = np.array(combi[0:2]) * (vect * dif_mean_out_in * (i*0.06) * perturb_direction[0:2])\n",
    "                    perturb2 = np.array(combi[2]) * (dif_mean_pkts * (i*0.25) * perturb_direction[1])\n",
    "                    perturb3 = np.array(combi[3]) * (dif_mean_dur * (i*0.01) * perturb_direction[2])\n",
    "                    \n",
    "                    # Addition of crafted perturbation\n",
    "                    adv[7] = adv[7] + perturb1[1] # InBytes\n",
    "                    adv[6] = adv[6] + perturb1[0] # OutBytes\n",
    "                    adv[2] = adv[2] + perturb3 # Duration\n",
    "                    adv[8] = adv[8] + perturb2 # Tot Packets # cast in INT to keep only the integer value\n",
    "                    \n",
    "                    # Syntactic Constraints\n",
    "                    # Add projection on the max value present in the dataset to keep the physical limitation\n",
    "                    if(adv[2] > max_dur):\n",
    "                        adv[2] = max_dur\n",
    "                    if(adv[6] > max_out):\n",
    "                        adv[6] = max_out\n",
    "                    if(adv[7] > max_in):\n",
    "                        adv[7] = max_in\n",
    "                    if(adv[8] > max_pkts):\n",
    "                        adv[8] = max_pkts\n",
    "                    \n",
    "                    # Add the Semantic Contraints\n",
    "                    # Total number of Bytes in the communication. Sum of OutBytes and InBytes feature values.\n",
    "                    adv[9] = adv[6]+adv[7] # TotBytes\n",
    "                    # Average number of bytes exchanged per packet. Ratio between TotBytes and TotPkts.\n",
    "                    adv[11] = adv[9]/adv[8] # BytesPerPkt\n",
    "                    # Average number of bytes exchanged per second. Ratio between TotBytes and Duration.\n",
    "                    adv[10] = adv[9]/adv[2] # BytesPerSec\n",
    "                    # Average number of packets exchanged per second. Ratio between TotPkts and Duration.\n",
    "                    adv[12] = adv[8]/adv[2]\n",
    "                    \n",
    "                    # Ratio between OutBytes and InBytes\n",
    "                    if(adv[7] == 0 and adv[6] != 0):\n",
    "                        adv[13] = max_ratio # It's the maximum value in the dataset to replace the undefined value when x/0\n",
    "                    # If In and Out = 0, ratio is 0. 0/0 (Maybe not necessary)\n",
    "                    if(adv[7] == 0 and adv[6] == 0):\n",
    "                        adv[13] = 0\n",
    "                    # Ratio by default when inbytes has a value x/y\n",
    "                    if(adv[7] != 0):\n",
    "                        adv[13] = adv[6]/adv[7] # Ratio Out/In\n",
    "                    # if there is new bytes, normaly there is also at least 1 packet\n",
    "                    if(adv[8] == 0 and adv[9] > 0):\n",
    "                        adv[8] = 1 # Maybe change this part\n",
    "                        \n",
    "                    adv2 = [] # used to fit with the input of the model because normaly take a matrix, so need the matrix notation, even for a vector\n",
    "                    adv2.append(adv)\n",
    "                    \n",
    "                    adv2_scaled = scaler.transform(adv2) # For DNN\n",
    "                    test = model_input.predict(adv2_scaled)\n",
    "                    test = np.argmax(test,1) # For DNN\n",
    "                    #test = model_input.predict(adv2) # For other model than DNN\n",
    "                    if (test == 0): # benign break\n",
    "                        adv_ex.append(adv) # adv_ex contains all adversarial examples that fool the classifier\n",
    "                        breaked = True\n",
    "                        tot_masks.append(index_of_mask)\n",
    "                        tot_nb_of_steps.append(nb_of_needed_step)\n",
    "                        break\n",
    "            index_of_mask = 0\n",
    "        nb_of_needed_step = 0            \n",
    "        total_ex.append(adv) # Total adversarial examples. append the final created adv ex that fool or not \n",
    "        bar()\n",
    "        \n",
    "end = time.process_time()-start\n",
    "print(\"Time taken to generate: \" + str(end) + \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844ec723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation \n",
    "\n",
    "# Adversarial prediction on DNN Defender\n",
    "\n",
    "mean_steps = np.mean(tot_nb_of_steps)\n",
    "print(\"The mean steps needed to generate adv examples is: \" + str(round(mean_steps,1)))\n",
    "\n",
    "# total_ex_pd = pd.DataFrame(total_ex, columns = mal_dataset.columns) # To see distributions\n",
    "truevalue = np.ones(len(total_ex)) # Recover the true value (all 1 because all malicious)\n",
    "total_ex_scaled = scaler.transform(total_ex) # For DNN\n",
    "pred = model.predict(total_ex_scaled) \n",
    "# pred = model.predict(total_ex)\n",
    "pred = np.argmax(pred,1) # For DNN\n",
    "\n",
    "matrix = classification_report(y_true=truevalue, y_pred=pred)\n",
    "print(matrix)\n",
    "\n",
    "# Distribution of the steps to generate adv ex\n",
    "\n",
    "plt.rcParams.update({'figure.figsize':(7,5), 'figure.dpi':100})\n",
    "\n",
    "# Plot Histogram\n",
    "plt.hist(tot_nb_of_steps, bins=30)\n",
    "plt.gca().set(title='Step distribution', ylabel='Frequency');\n",
    "\n",
    "# Distribution of masks used to generate adv ex\n",
    "\n",
    "# Plot Histogram\n",
    "plt.hist(tot_masks, bins=30)\n",
    "plt.gca().set(title='Mask distribution', ylabel='Frequency');\n",
    "\n",
    "# Compute the average perturbation rate\n",
    "perturb_diff = total_ex - mal_dataset_reduced.to_numpy()\n",
    "perturb_diff_mean = np.mean(perturb_diff,axis=0)\n",
    "perturb_diff_max = np.max(perturb_diff,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e8295ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'CTU/defense/mlp/attacker_adv_instances.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12688/1419707082.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# Adversarial instances recovering - ONLY USE TO RECOVER ADV INSTANCES\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0madv_ex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpkl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/defense/mlp/attacker_adv_instances.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[0madv_ex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madv_ex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"Label\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mtotal_ex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madv_ex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'CTU/defense/mlp/attacker_adv_instances.pkl'"
     ]
    }
   ],
   "source": [
    "# Post processing + Exports adversarial and clean sets (for attacker)\n",
    "# Convert to Pandas dataframe\n",
    "adv_instances = pd.DataFrame(adv_ex, columns = mal_dataset_reduced.columns)\n",
    "# Relabelisation of adversarial and non-adversarial instances\n",
    "labelised_adv_instances = adv_instances.assign(Label=1)\n",
    "# Save Adversarial dataset        \n",
    "pkl.dump(labelised_adv_instances, open(ds + '/defense/defender_test_adv_instances.pkl', 'wb'))\n",
    "\n",
    "# Concat clean (malicious + benign dataset) dataset\n",
    "clean_instances = pd.concat([ben_dataset.drop(columns = [\"Label\"])[:1250], mal_dataset_reduced[:1250]], ignore_index = True)\n",
    "# Relabelisation of adversarial and non-adversarial instances\n",
    "labelised_clean_instances = clean_instances.assign(Label=0)\n",
    "# Save dataset\n",
    "pkl.dump(labelised_clean_instances, open(ds + '/defense/defender_test_clean_instances.pkl', 'wb'))\n",
    "\n",
    "# Exports distributions of attack\n",
    "pkl.dump(tot_nb_of_steps, open(ds + '/defense/attacker_nb_steps.pkl', 'wb'))\n",
    "pkl.dump(tot_masks, open(ds + '/defense/attacker_masks.pkl', 'wb'))\n",
    "\n",
    "# Adversarial instances recovering - ONLY USE TO RECOVER ADV INSTANCES\n",
    "adv_ex = pkl.load(open(ds + '/defense/mlp/attacker_adv_instances.pkl', 'rb'))\n",
    "adv_ex = adv_ex.drop(columns = [\"Label\"])\n",
    "total_ex = adv_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c45f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exports instances for the defense\n",
    "\n",
    "# Exports benign sets (for defender)\n",
    "# TRAIN\n",
    "# pkl.dump(ben_dataset.drop(columns = [\"Label\"])[:4000], open(ds + '/defense/benign_train_instances.pkl', 'wb'))\n",
    "\n",
    "# TEST\n",
    "# pkl.dump(ben_dataset.drop(columns = [\"Label\"])[:1000], open(ds + '/defense/benign_test_instances.pkl', 'wb'))\n",
    "\n",
    "# Exports adversarial and malicious sets (for defender)\n",
    "\n",
    "# Labelised after, when all adversarial examples are generated\n",
    "\n",
    "# export malicious set (TRAIN)\n",
    "pkl.dump(mal_dataset_reduced[:2000], open(ds + '/defense/'+botnet[attackindex]+'/train_mal_instances.pkl', 'wb'))\n",
    " \n",
    "# export adversarial set (TRAIN)\n",
    "pkl.dump(adv_ex, open(ds + '/defense/'+botnet[attackindex]+'/train_adv_instances.pkl', 'wb'))      \n",
    "\n",
    "# export malicious set (TEST)\n",
    "#pkl.dump(mal_dataset_reduced[:500], open(ds + '/defense/'+botnet[attackindex]+'/test_mal_instances.pkl', 'wb'))\n",
    "\n",
    "# export adversarial set (TEST)\n",
    "#pkl.dump(adv_ex, open(ds + '/defense/'+botnet[attackindex]+'/test_adv_instances.pkl', 'wb'))  \n",
    "\n",
    "# Post processing, replace train by test or the reverse\n",
    "mal_instances_all = pd.DataFrame()\n",
    "\n",
    "# malicious concat\n",
    "for bot in botnet:\n",
    "    mal_instances = pkl.load(open(ds + '/defense/'+bot+'/test_mal_instances.pkl', 'rb'))\n",
    "    mal_instances_all = pd.concat([mal_instances_all, mal_instances], ignore_index = True)\n",
    "    \n",
    "# benign concat + clean_instances label\n",
    "ben_instances = pkl.load(open(ds + '/defense/test_benign_instances.pkl', 'rb'))\n",
    "\n",
    "clean_instances = pd.concat([mal_instances_all, ben_instances], ignore_index = True)\n",
    "\n",
    "labelised_clean_instances = clean_instances.assign(Label=0)\n",
    "\n",
    "pkl.dump(labelised_clean_instances, open(ds + '/defense/defender_test_clean_instances.pkl', 'wb'))\n",
    "\n",
    "\n",
    "adv_instances_all = pd.DataFrame()\n",
    "\n",
    "# adv instances concat\n",
    "for bot in botnet:\n",
    "    adv_instances = pkl.load(open(ds + '/defense/'+bot+'/test_adv_instances.pkl', 'rb'))\n",
    "    adv_instances_pd = pd.DataFrame(adv_instances, columns = mal_instances_all.columns)\n",
    "    adv_instances_all = pd.concat([adv_instances_all, adv_instances_pd], ignore_index=True)\n",
    "    \n",
    "labelised_adv_instances = adv_instances_all.assign(Label=1)\n",
    "\n",
    "pkl.dump(labelised_adv_instances, open(ds + '/defense/defender_test_adv_instances.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2342d7e2",
   "metadata": {},
   "source": [
    "# Defense - Adversarial detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6339518a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "\n",
    "# For CTU and BOTNET\n",
    "'''modifiablefeature = [2,6,7,8]\n",
    "dependantfeature = [9,10,11,12,13]\n",
    "nonmodifiablefeature = [0,1,3,4,5,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37]'''\n",
    "\n",
    "# For CICIDS2018\n",
    "modifiablefeature = [0,1,2,3]\n",
    "dependantfeature = [4,5,6,7,8]\n",
    "nonmodifiablefeature = [9,10,11,12]\n",
    "\n",
    "feature_map = []\n",
    "feature_map.append(modifiablefeature)\n",
    "feature_map.append(dependantfeature)\n",
    "feature_map.append(nonmodifiablefeature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3ecceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for training and testing (Defender)\n",
    "# Recover train and test set containing adversarial and non-adversarial instances\n",
    "labelised_adv_instances_train = pkl.load(open(ds + '/defense/defender_train_adv_instances.pkl', 'rb'))\n",
    "labelised_clean_instances_train = pkl.load(open(ds + '/defense/defender_train_clean_instances.pkl', 'rb'))\n",
    "\n",
    "labelised_adv_instances_test = pkl.load(open(ds + '/defense/defender_test_adv_instances.pkl', 'rb'))\n",
    "labelised_clean_instances_test = pkl.load(open(ds + '/defense/defender_test_clean_instances.pkl', 'rb'))\n",
    "\n",
    "# Concatenation of adversarial and non-adversarial instances\n",
    "labelised_instances_train = pd.concat([labelised_adv_instances_train, labelised_clean_instances_train], ignore_index = True)\n",
    "labelised_instances_train = shuffle(labelised_instances_train)\n",
    "\n",
    "labelised_instances_test = pd.concat([labelised_adv_instances_test, labelised_clean_instances_test], ignore_index = True)\n",
    "labelised_instances_test = shuffle(labelised_instances_test)\n",
    "\n",
    "# Adversarial and non-adversarial X_train of the defender to train\n",
    "X_train_adv = labelised_instances_train.drop(columns = [\"Label\"])\n",
    "y_train_adv = labelised_instances_train.Label\n",
    "\n",
    "# Adversarial and non-adversarial X_test of the defender to evaluate\n",
    "X_test_adv = labelised_instances_test.drop(columns = [\"Label\"])\n",
    "y_test_adv = labelised_instances_test.Label\n",
    "\n",
    "# Normalization\n",
    "scaler3 = MinMaxScaler()\n",
    "scaler3.fit(X_train_adv.to_numpy())\n",
    "X_train_adv_scaled = scaler3.transform(X_train_adv)\n",
    "X_test_adv_scaled = scaler3.transform(X_test_adv) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b12f236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for testing (Attacker)\n",
    "labelised_adv_instances_attacker_test = pkl.load(open(ds + '/attack/' + botnet[attackindex] + '/rf/attacker_adv_instances.pkl', 'rb'))\n",
    "labelised_clean_instances_attacker_test = pkl.load(open(ds + '/attack/' + botnet[attackindex] + '/rf/attacker_clean_instances.pkl', 'rb'))\n",
    "\n",
    "#labelised_instances_attacker_test = pd.concat([labelised_adv_instances_attacker_test, labelised_clean_instances_attacker_test], ignore_index = True)\n",
    "#labelised_instances_attacker_test = shuffle(labelised_instances_attacker_test)\n",
    "\n",
    "X_test_adv_attacker = labelised_adv_instances_attacker_test.drop(columns = [\"Label\"])\n",
    "y_test_adv_attacker = labelised_adv_instances_attacker_test.Label\n",
    "\n",
    "X_test_adv_attacker_scaled = scaler2.transform(X_test_adv_attacker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8e418a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Clusters Training - MLP\n",
    "\n",
    "all_cluster = []\n",
    "\n",
    "y_train_adv_ohe = pd.get_dummies(y_train_adv)\n",
    "y_train_adv_ohe_tf = tf.convert_to_tensor(y_train_adv_ohe, np.float32)\n",
    "\n",
    "y_test_adv_ohe = pd.get_dummies(y_test_adv)\n",
    "y_test_adv_ohe_tf = tf.convert_to_tensor(y_test_adv_ohe, np.float32)\n",
    "\n",
    "for features in feature_map:\n",
    "    # Take feature for each cluster\n",
    "    X_train_defender_scaled_cluster = X_train_adv_scaled[:, features]\n",
    "    X_test_defender_scaled_cluster = X_test_adv_scaled[:, features] \n",
    "        \n",
    "    output_number = 2\n",
    "    eval_metric = 'categorical_accuracy'\n",
    "    loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "    activ_out = 'softmax'\n",
    "    neurons_number = 256\n",
    "    lr = 0.01\n",
    "    features_number = X_train_defender_scaled_cluster.shape[1]\n",
    "    \n",
    "    cluster = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(neurons_number, input_shape=(features_number,), activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(neurons_number, activation=\"relu\"),\n",
    "        # tf.keras.layers.Dense(neurons_number, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(output_number, activation=activ_out)\n",
    "    ])\n",
    "    cluster.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "        loss = weighted_binary_crossentropy,\n",
    "        metrics=[eval_metric]\n",
    "    )\n",
    "    \n",
    "    \n",
    "    cluster.fit(x=X_train_defender_scaled_cluster, y=y_train_adv_ohe_tf, epochs=10, batch_size=100, verbose=1)\n",
    "    cluster.evaluate(x=X_test_defender_scaled_cluster, y=y_test_adv_ohe_tf, verbose=1)\n",
    "    \n",
    "    all_cluster.append(cluster)\n",
    "    \n",
    "# Model saving \n",
    "# pkl.dump(all_cluster, open('detectordefender.pkl', 'wb'))\n",
    "\n",
    "# Clusters evaluation\n",
    "\n",
    "# Model Loading\n",
    "# all_cluster = pkl.load(open('detectordefender.pkl', 'rb'))\n",
    "\n",
    "recalls = []\n",
    "\n",
    "i = 0\n",
    "# Evaluation\n",
    "for cluster in all_cluster:\n",
    "    X_test_defender_scaled_cluster = X_test_adv_scaled[:, feature_map[i]] \n",
    "    y_pred = cluster.predict(X_test_defender_scaled_cluster)\n",
    "    y_pred_vect = np.argmax(y_pred,1)\n",
    "    print(classification_report(y_true=y_test_adv, y_pred=y_pred_vect))\n",
    "    metric_matrix = classification_report(output_dict = True, y_true=y_test_adv, y_pred=y_pred_vect)\n",
    "    # extract recall and round to 2 after ,\n",
    "    recalls.append(round(metric_matrix['weighted avg']['recall'],2))\n",
    "    \n",
    "    i+=1\n",
    "    \n",
    "# Recall extraction to set defensive wieghts (as importance of recall)\n",
    "defensive_weights = recalls\n",
    "   \n",
    "    \n",
    "#%% Attack part - Contextual Discounting (Cluster - Output decision)\n",
    "\n",
    "# set must be chosen (defender adv test to evaluate or attacker adv)\n",
    "X_adv_scaled = X_test_adv_attacker_scaled\n",
    "y_adv = y_test_adv_attacker\n",
    "\n",
    "'''X_adv_scaled = X_test_adv_scaled\n",
    "y_adv = y_test_adv'''\n",
    "\n",
    "cluster_pred = []\n",
    "\n",
    "i = 0\n",
    "for cluster in all_cluster:\n",
    "    # Multiplication of probs by their defensive weights\n",
    "    X_defender_scaled_cluster = X_adv_scaled[:, feature_map[i]] \n",
    "    y_pred = cluster.predict(X_defender_scaled_cluster)\n",
    "    y_pred = y_pred * defensive_weights[i]\n",
    "    \n",
    "    cluster_pred.append(y_pred)\n",
    "    \n",
    "    i+=1\n",
    "    \n",
    "    \n",
    "#%% Scaling to have 100% using Bayes theorem for the fusion \n",
    "\n",
    "all_fusion = []\n",
    "\n",
    "# Bayesian fusion, sum of clusters probabilities \n",
    "preds = sum(cluster_pred)\n",
    "\n",
    "# Normalization, for each prediction summed before, normalization in function of the class importance\n",
    "for pred in preds:\n",
    "    fusion = pred/sum(pred)\n",
    "    all_fusion.append(fusion)\n",
    "\n",
    "# Take only the class number (transform logits in decision)\n",
    "detector_predicted_class = np.argmax(all_fusion, axis=1)\n",
    "    \n",
    "# General evaluation of the detector after fusion\n",
    "\n",
    "print(classification_report(y_true=y_adv, y_pred=detector_predicted_class)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f24cdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Evaluation on the defender IDS with detector\n",
    "\n",
    "# Extract all adversarial instances that passed the detector\n",
    "\n",
    "passed_adv_ex = y_adv == detector_predicted_class\n",
    "passed_adv_ex = passed_adv_ex[passed_adv_ex==False]\n",
    "\n",
    "# Recover instances from dataset\n",
    "joined_passed_adv_ex = X_test_adv_attacker.join(passed_adv_ex, how='inner')\n",
    "\n",
    "# Relabel as malicious (normaly IDS will classify this instance as benign, but not sure with transerability)\n",
    "joined_passed_adv_ex = joined_passed_adv_ex.assign(Label=1)\n",
    "\n",
    "# Concat with original test set\n",
    "new_X_test_defender = pd.concat([joined_passed_adv_ex, test_defender], ignore_index = True)\n",
    "new_X_test_defender = shuffle(new_X_test_defender)\n",
    "\n",
    "# Extract Label\n",
    "new_y_test_defender = new_X_test_defender.Label\n",
    "\n",
    "# Evaluate on the Defender MLP (IDS)\n",
    "model = tf.keras.models.load_model(ds + '/models/dnndefender', custom_objects={'weighted_binary_crossentropy': weighted_binary_crossentropy})\n",
    "\n",
    "# Evaluation\n",
    "new_X_test_defender_scaled = scaler2.transform(new_X_test_defender.drop(columns = [\"Label\"])) \n",
    "\n",
    "y_pred = model.predict(new_X_test_defender_scaled)\n",
    "y_pred_vect = np.argmax(y_pred,1)\n",
    "print(classification_report(y_true=new_y_test_defender, y_pred=y_pred_vect))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
